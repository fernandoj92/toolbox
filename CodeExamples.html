<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="UTF-8">
    <title>AMIDST Toolbox 2.0 by amidst</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheets/normalize.css" media="screen">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">AMIDST Toolbox 2.0</h1>
      <h2 class="project-tagline">A Java Toolbox for Analysis of MassIve Data STreams using Probabilistic Graphical Models</h2>
      <a href="https://github.com/amidst/toolbox" class="btn">View on GitHub</a>
      <a href="https://github.com/amidst/toolbox/zipball/master" class="btn">Download .zip</a>
      <a href="https://github.com/amidst/toolbox/tarball/master" class="btn">Download .tar.gz</a>
    </section>

    <section class="main-content">
      <h2>
<a id="bayesian-networks-code-examples" class="anchor" href="#bayesian-networks-code-examples" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Bayesian Networks: Code Examples<a name="documentation"></a>
</h2>

<ul>
<li><a href="#datastreamsexample">Data Streams</a></li>
<li><a href="#variablesexample">Random Variables</a></li>
<li>
<a href="#bnexample">Bayesian Networks</a>

<ul>
<li><a href="#bnnohiddenexample">Creating Bayesian Networks</a></li>
<li><a href="#bnhiddenexample">Creating Bayesian Networks with latent variables</a></li>
<li><a href="#bnmodifyexample">Modifying Bayesian Networks</a></li>
</ul>
</li>
<li>
<a href="#ioexample">I/O Functionality</a>

<ul>
<li><a href="#iodatastreamsexample">I/O of Data Streams</a></li>
<li><a href="#iobnsexample">I/O of Bayesian Networks</a></li>
</ul>
</li>
<li>
<a href="#inferenceexample">Inference Algorithms</a>

<ul>
<li><a href="#inferenceengingeexample">The Inference Engine</a></li>
<li><a href="#vmpexample">Variational Message Passing</a></li>
<li><a href="#isexample">Importance Sampling</a></li>
</ul>
</li>
<li>
<a href="#learningexample">Learning Algorithms</a>

<ul>
<li><a href="#mlexample">Maximum Likelihood</a></li>
<li><a href="#pmlexample">Parallel Maximum Likelihood</a></li>
<li><a href="#svbexample">Streaming Variational Bayes</a></li>
<li><a href="#psvbexample">Parallel Streaming Variational Bayes</a></li>
</ul>
</li>
<li>
<a href="#conceptdriftexample">Concept Drift Methods</a>

<ul>
<li><a href="#nbconceptdriftexample">Naive Bayes with Virtual Concept Drift Detection</a></li>
</ul>
</li>
<li>
<a href="#huginglinkexample">HuginLink</a>

<ul>
<li><a href="#huginglinkconversionexample">Models conversion between AMIDST and Hugin</a></li>
<li><a href="#huginglinkioexample">I/O of Bayesian Networks with Hugin net format</a></li>
<li><a href="#huginglinkinferenceexample">Invoking Hugin's inference engine</a></li>
<li><a href="#huginglinkTANexample">Invoking Hugin's Parallel TAN</a></li>
</ul>
</li>
<li>
<a href="#moalinkexample">MoaLink</a>

<ul>
<li><a href="#moalinkclassifiersexample">AMIDST Classifiers from MOA</a></li>
<li><a href="#moalinkregressionsexample">AMIDST Regression from MOA</a></li>
</ul>
</li>
</ul>

<h2>
<a id="data-streams" class="anchor" href="#data-streams" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Data Streams<a name="datastreamsexample"></a>
</h2>

<p>In this example we show how to use the main features of a <em>DataStream</em> object. More precisely,  we show six different ways of iterating over the data samples of a <em>DataStream</em> object.</p>

<div class="highlight highlight-source-java"><pre><span class="pl-c">//We can open the data stream using the static class DataStreamLoader</span>
<span class="pl-k">DataStream&lt;<span class="pl-smi">DataInstance</span>&gt;</span> data <span class="pl-k">=</span> <span class="pl-smi">DataStreamLoader</span><span class="pl-k">.</span>openFromFile(<span class="pl-s"><span class="pl-pds">"</span>datasets/SmallDataSet.arff<span class="pl-pds">"</span></span>);

<span class="pl-c">//Access to the attributes defining the data set</span>
<span class="pl-smi">System</span><span class="pl-k">.</span>out<span class="pl-k">.</span>println(<span class="pl-s"><span class="pl-pds">"</span>Attributes defining the data set<span class="pl-pds">"</span></span>);
<span class="pl-k">for</span> (<span class="pl-smi">Attribute</span> attribute <span class="pl-k">:</span> data<span class="pl-k">.</span>getAttributes()) {
    <span class="pl-smi">System</span><span class="pl-k">.</span>out<span class="pl-k">.</span>println(attribute<span class="pl-k">.</span>getName());
}
<span class="pl-smi">Attribute</span> attA <span class="pl-k">=</span> data<span class="pl-k">.</span>getAttributes()<span class="pl-k">.</span>getAttributeByName(<span class="pl-s"><span class="pl-pds">"</span>A<span class="pl-pds">"</span></span>);

<span class="pl-c">//1. Iterating over samples using a for loop</span>
<span class="pl-smi">System</span><span class="pl-k">.</span>out<span class="pl-k">.</span>println(<span class="pl-s"><span class="pl-pds">"</span>1. Iterating over samples using a for loop<span class="pl-pds">"</span></span>);
<span class="pl-k">for</span> (<span class="pl-smi">DataInstance</span> dataInstance <span class="pl-k">:</span> data) {
    <span class="pl-smi">System</span><span class="pl-k">.</span>out<span class="pl-k">.</span>println(<span class="pl-s"><span class="pl-pds">"</span>The value of attribute A for the current data instance is: <span class="pl-pds">"</span></span> <span class="pl-k">+</span>
                                                          dataInstance<span class="pl-k">.</span>getValue(attA));
}


<span class="pl-c">//2. Iterating using streams. We need to restart the data again </span>
<span class="pl-c">//   as a DataStream can only be used once.</span>
<span class="pl-smi">System</span><span class="pl-k">.</span>out<span class="pl-k">.</span>println(<span class="pl-s"><span class="pl-pds">"</span>2. Iterating using streams.<span class="pl-pds">"</span></span>);
data<span class="pl-k">.</span>restart();
data<span class="pl-k">.</span>stream()<span class="pl-k">.</span>forEach(dataInstance <span class="pl-k">-</span><span class="pl-k">&gt;</span>
                <span class="pl-smi">System</span><span class="pl-k">.</span>out<span class="pl-k">.</span>println(<span class="pl-s"><span class="pl-pds">"</span>The value of attribute A for the current data <span class="pl-pds">"</span></span><span class="pl-k">+</span>
                                        instance is<span class="pl-k">:</span> <span class="pl-s"><span class="pl-pds">"</span> + dataInstance.getValue(attA))</span>
<span class="pl-s">);</span>
<span class="pl-s"></span>
<span class="pl-s"></span>
<span class="pl-s">//3. Iterating using parallel streams.</span>
<span class="pl-s">System.out.println(<span class="pl-pds">"</span></span><span class="pl-c1">3.</span> <span class="pl-smi">Iterating</span> using parallel streams<span class="pl-k">.</span><span class="pl-s"><span class="pl-pds">"</span>);</span>
<span class="pl-s">data.restart();</span>
<span class="pl-s">data.parallelStream(10).forEach(dataInstance -&gt;</span>
<span class="pl-s">                System.out.println(<span class="pl-pds">"</span></span><span class="pl-smi">The</span> value of attribute <span class="pl-smi">A</span> <span class="pl-k">for</span> the current data <span class="pl-s"><span class="pl-pds">"</span>+</span>
<span class="pl-s">                                        instance is: <span class="pl-pds">"</span></span> <span class="pl-k">+</span> dataInstance<span class="pl-k">.</span>getValue(attA))
);

<span class="pl-c">//4. Iterating over a stream of data batches.</span>
<span class="pl-smi">System</span><span class="pl-k">.</span>out<span class="pl-k">.</span>println(<span class="pl-s"><span class="pl-pds">"</span>4. Iterating over a stream of data batches.<span class="pl-pds">"</span></span>);
data<span class="pl-k">.</span>restart();
data<span class="pl-k">.</span>streamOfBatches(<span class="pl-c1">10</span>)<span class="pl-k">.</span>forEach(batch <span class="pl-k">-</span><span class="pl-k">&gt;</span> {
    <span class="pl-k">for</span> (<span class="pl-smi">DataInstance</span> dataInstance <span class="pl-k">:</span> batch)
                <span class="pl-smi">System</span><span class="pl-k">.</span>out<span class="pl-k">.</span>println(<span class="pl-s"><span class="pl-pds">"</span>The value of attribute A for the current data <span class="pl-pds">"</span></span><span class="pl-k">+</span>
                                        instance is<span class="pl-k">:</span> <span class="pl-s"><span class="pl-pds">"</span> + dataInstance.getValue(attA))</span>
<span class="pl-s">});</span>
<span class="pl-s"></span>
<span class="pl-s">//5. Iterating over a parallel stream of data batches.</span>
<span class="pl-s">System.out.println(<span class="pl-pds">"</span></span><span class="pl-c1">5.</span> <span class="pl-smi">Iterating</span> over a parallel stream of data batches<span class="pl-k">.</span><span class="pl-s"><span class="pl-pds">"</span>);</span>
<span class="pl-s">data.restart();</span>
<span class="pl-s">data.parallelStreamOfBatches(10).forEach(batch -&gt; {</span>
<span class="pl-s">    for (DataInstance dataInstance : batch)</span>
<span class="pl-s">                System.out.println(<span class="pl-pds">"</span></span><span class="pl-smi">The</span> value of attribute <span class="pl-smi">A</span> <span class="pl-k">for</span> the current data <span class="pl-s"><span class="pl-pds">"</span>+</span>
<span class="pl-s">                                        instance is: <span class="pl-pds">"</span></span> <span class="pl-k">+</span> dataInstance<span class="pl-k">.</span>getValue(attA))
});


<span class="pl-c">//6. Iterating over data batches using a for loop</span>
<span class="pl-smi">System</span><span class="pl-k">.</span>out<span class="pl-k">.</span>println(<span class="pl-s"><span class="pl-pds">"</span>6. Iterating over data batches using a for loop.<span class="pl-pds">"</span></span>);
<span class="pl-k">for</span> (<span class="pl-k">DataOnMemory&lt;<span class="pl-smi">DataInstance</span>&gt;</span> batch <span class="pl-k">:</span> data<span class="pl-k">.</span>iterableOverBatches(<span class="pl-c1">10</span>)) {
    <span class="pl-k">for</span> (<span class="pl-smi">DataInstance</span> dataInstance <span class="pl-k">:</span> batch)
                <span class="pl-smi">System</span><span class="pl-k">.</span>out<span class="pl-k">.</span>println(<span class="pl-s"><span class="pl-pds">"</span>The value of attribute A for the current data <span class="pl-pds">"</span></span><span class="pl-k">+</span>
                                        instance is<span class="pl-k">:</span> <span class="pl-s"><span class="pl-pds">"</span> + dataInstance.getValue(attA))</span>
<span class="pl-s">}</span></pre></div>

<p><a href="#documentation">[Back to Top]</a></p>

<h2>
<a id="random-variables" class="anchor" href="#random-variables" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Random Variables<a name="variablesexample"></a>
</h2>

<p>This example show the basic functionality of the classes Variables and Variable.</p>

<div class="highlight highlight-source-java"><pre><span class="pl-c">//We first create an empty Variables object</span>
<span class="pl-smi">Variables</span> variables <span class="pl-k">=</span> <span class="pl-k">new</span> <span class="pl-smi">Variables</span>();

<span class="pl-c">//We invoke the "new" methods of the object Variables to create new variables.</span>
<span class="pl-c">//Now we create a Gaussian variables</span>
<span class="pl-smi">Variable</span> gaussianVar <span class="pl-k">=</span> variables<span class="pl-k">.</span>newGaussianVariable(<span class="pl-s"><span class="pl-pds">"</span>Gaussian<span class="pl-pds">"</span></span>);

<span class="pl-c">//Now we create a Multinomial variable with two states</span>
<span class="pl-smi">Variable</span> multinomialVar <span class="pl-k">=</span> variables<span class="pl-k">.</span>newMultionomialVariable(<span class="pl-s"><span class="pl-pds">"</span>Multinomial<span class="pl-pds">"</span></span>, <span class="pl-c1">2</span>);

<span class="pl-c">//Now we create a Multinomial variable with two states: TRUE and FALSE</span>
<span class="pl-smi">Variable</span> multinomialVar2 <span class="pl-k">=</span> variables<span class="pl-k">.</span>newMultionomialVariable(<span class="pl-s"><span class="pl-pds">"</span>Multinomial2<span class="pl-pds">"</span></span>, 
                                                <span class="pl-smi">Arrays</span><span class="pl-k">.</span>asList(<span class="pl-s"><span class="pl-pds">"</span>TRUE, FALSE<span class="pl-pds">"</span></span>));

<span class="pl-c">//For Multinomial variables we can iterate over their different states</span>
<span class="pl-smi">FiniteStateSpace</span> states <span class="pl-k">=</span> multinomialVar2<span class="pl-k">.</span>getStateSpaceType();
states<span class="pl-k">.</span>getStatesNames()<span class="pl-k">.</span>forEach(<span class="pl-smi">System</span><span class="pl-k">.</span>out<span class="pl-k">::</span>println);

<span class="pl-c">//Variable objects can also be used, for example, to know if one variable </span>
<span class="pl-c">//can be set as parent of some other variable</span>
<span class="pl-smi">System</span><span class="pl-k">.</span>out<span class="pl-k">.</span>println(<span class="pl-s"><span class="pl-pds">"</span>Can a Gaussian variable be parent of Multinomial variable? <span class="pl-pds">"</span></span> <span class="pl-k">+</span>
        (multinomialVar<span class="pl-k">.</span>getDistributionType()<span class="pl-k">.</span>isParentCompatible(gaussianVar)));

<span class="pl-smi">System</span><span class="pl-k">.</span>out<span class="pl-k">.</span>println(<span class="pl-s"><span class="pl-pds">"</span>Can a Multinomial variable be parent of Gaussian variable? <span class="pl-pds">"</span></span> <span class="pl-k">+</span>
        (gaussianVar<span class="pl-k">.</span>getDistributionType()<span class="pl-k">.</span>isParentCompatible(multinomialVar)));</pre></div>

<p><a href="#documentation">[Back to Top]</a></p>

<h2>
<a id="bayesian-networks" class="anchor" href="#bayesian-networks" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Bayesian Networks<a name="bnexample"></a>
</h2>

<h3>
<a id="creating-bayesian-networks" class="anchor" href="#creating-bayesian-networks" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Creating Bayesian Networks<a name="bnnohiddenexample"></a>
</h3>

<p>In this example, we take a data set, create a BN and we compute the log-likelihood of all the samples
of this data set. The numbers defining the probability distributions of the BN are randomly fixed.</p>

<div class="highlight highlight-source-java"><pre><span class="pl-c">//We can open the data stream using the static class DataStreamLoader</span>
<span class="pl-k">DataStream&lt;<span class="pl-smi">DataInstance</span>&gt;</span> data <span class="pl-k">=</span> <span class="pl-smi">DataStreamLoader</span><span class="pl-k">.</span>openFromFile(<span class="pl-s"><span class="pl-pds">"</span>datasets/syntheticData.arff<span class="pl-pds">"</span></span>);


<span class="pl-c">/**</span>
<span class="pl-c"> * 1. Once the data is loaded, we create a random variable for each of the attributes (i.e. data columns)</span>
<span class="pl-c"> * in our data.</span>
<span class="pl-c"> *</span>
<span class="pl-c"> * 2. {@link Variables} is the class for doing that. It takes a list of Attributes and internally creates</span>
<span class="pl-c"> * all the variables. We create the variables using Variables class to guarantee that each variable</span>
<span class="pl-c"> * has a different ID number and make it transparent for the user.</span>
<span class="pl-c"> *</span>
<span class="pl-c"> * 3. We can extract the Variable objects by using the method getVariableByName();</span>
<span class="pl-c"> */</span>
<span class="pl-smi">Variables</span> variables <span class="pl-k">=</span> <span class="pl-k">new</span> <span class="pl-smi">Variables</span>(data<span class="pl-k">.</span>getAttributes());

<span class="pl-smi">Variable</span> a <span class="pl-k">=</span> variables<span class="pl-k">.</span>getVariableByName(<span class="pl-s"><span class="pl-pds">"</span>A<span class="pl-pds">"</span></span>);
<span class="pl-smi">Variable</span> b <span class="pl-k">=</span> variables<span class="pl-k">.</span>getVariableByName(<span class="pl-s"><span class="pl-pds">"</span>B<span class="pl-pds">"</span></span>);
<span class="pl-smi">Variable</span> c <span class="pl-k">=</span> variables<span class="pl-k">.</span>getVariableByName(<span class="pl-s"><span class="pl-pds">"</span>C<span class="pl-pds">"</span></span>);
<span class="pl-smi">Variable</span> d <span class="pl-k">=</span> variables<span class="pl-k">.</span>getVariableByName(<span class="pl-s"><span class="pl-pds">"</span>D<span class="pl-pds">"</span></span>);
<span class="pl-smi">Variable</span> e <span class="pl-k">=</span> variables<span class="pl-k">.</span>getVariableByName(<span class="pl-s"><span class="pl-pds">"</span>E<span class="pl-pds">"</span></span>);
<span class="pl-smi">Variable</span> g <span class="pl-k">=</span> variables<span class="pl-k">.</span>getVariableByName(<span class="pl-s"><span class="pl-pds">"</span>G<span class="pl-pds">"</span></span>);
<span class="pl-smi">Variable</span> h <span class="pl-k">=</span> variables<span class="pl-k">.</span>getVariableByName(<span class="pl-s"><span class="pl-pds">"</span>H<span class="pl-pds">"</span></span>);
<span class="pl-smi">Variable</span> i <span class="pl-k">=</span> variables<span class="pl-k">.</span>getVariableByName(<span class="pl-s"><span class="pl-pds">"</span>I<span class="pl-pds">"</span></span>);

<span class="pl-c">/**</span>
<span class="pl-c"> * 1. Once you have defined your {@link Variables} object, the next step is to create</span>
<span class="pl-c"> * a DAG structure over this set of variables.</span>
<span class="pl-c"> *</span>
<span class="pl-c"> * 2. To add parents to each variable, we first recover the ParentSet object by the method</span>
<span class="pl-c"> * getParentSet(Variable var) and then call the method addParent().</span>
<span class="pl-c"> */</span>
<span class="pl-smi">DAG</span> dag <span class="pl-k">=</span> <span class="pl-k">new</span> <span class="pl-smi">DAG</span>(variables);

dag<span class="pl-k">.</span>getParentSet(e)<span class="pl-k">.</span>addParent(a);
dag<span class="pl-k">.</span>getParentSet(e)<span class="pl-k">.</span>addParent(b);

dag<span class="pl-k">.</span>getParentSet(h)<span class="pl-k">.</span>addParent(a);
dag<span class="pl-k">.</span>getParentSet(h)<span class="pl-k">.</span>addParent(b);

dag<span class="pl-k">.</span>getParentSet(i)<span class="pl-k">.</span>addParent(a);
dag<span class="pl-k">.</span>getParentSet(i)<span class="pl-k">.</span>addParent(b);
dag<span class="pl-k">.</span>getParentSet(i)<span class="pl-k">.</span>addParent(c);
dag<span class="pl-k">.</span>getParentSet(i)<span class="pl-k">.</span>addParent(d);

dag<span class="pl-k">.</span>getParentSet(g)<span class="pl-k">.</span>addParent(c);
dag<span class="pl-k">.</span>getParentSet(g)<span class="pl-k">.</span>addParent(d);

<span class="pl-c">/**</span>
<span class="pl-c"> * 1. We first check if the graph contains cycles.</span>
<span class="pl-c"> *</span>
<span class="pl-c"> * 2. We print out the created DAG. We can check that everything is as expected.</span>
<span class="pl-c"> */</span>
<span class="pl-k">if</span> (dag<span class="pl-k">.</span>containCycles()) {
    <span class="pl-k">try</span> {
    } <span class="pl-k">catch</span> (<span class="pl-smi">Exception</span> ex) {
        <span class="pl-k">throw</span> <span class="pl-k">new</span> <span class="pl-smi">IllegalArgumentException</span>(ex);
    }
}

<span class="pl-smi">System</span><span class="pl-k">.</span>out<span class="pl-k">.</span>println(dag<span class="pl-k">.</span>toString());


<span class="pl-c">/**</span>
<span class="pl-c"> * 1. We now create the Bayesian network from the previous DAG.</span>
<span class="pl-c"> *</span>
<span class="pl-c"> * 2. The BN object is created from the DAG. It automatically looks at the distribution tye</span>
<span class="pl-c"> * of each variable and their parents to initialize the Distributions objects that are stored</span>
<span class="pl-c"> * inside (i.e. Multinomial, Normal, CLG, etc). The parameters defining these distributions are</span>
<span class="pl-c"> * properly initialized.</span>
<span class="pl-c"> *</span>
<span class="pl-c"> * 3. The network is printed and we can have look at the kind of distributions stored in the BN object.</span>
<span class="pl-c"> */</span>
<span class="pl-smi">BayesianNetwork</span> bn <span class="pl-k">=</span> <span class="pl-k">new</span> <span class="pl-smi">BayesianNetwork</span>(dag);
<span class="pl-smi">System</span><span class="pl-k">.</span>out<span class="pl-k">.</span>println(bn<span class="pl-k">.</span>toString());


<span class="pl-c">/**</span>
<span class="pl-c"> * 1. We iterate over the data set sample by sample.</span>
<span class="pl-c"> *</span>
<span class="pl-c"> * 2. For each sample or DataInstance object, we compute the log of the probability that the BN object</span>
<span class="pl-c"> * assigns to this observation.</span>
<span class="pl-c"> *</span>
<span class="pl-c"> * 3. We accumulate these log-probs and finally we print the log-prob of the data set.</span>
<span class="pl-c"> */</span>
<span class="pl-k">double</span> logProb <span class="pl-k">=</span> <span class="pl-c1">0</span>;
<span class="pl-k">for</span> (<span class="pl-smi">DataInstance</span> instance <span class="pl-k">:</span> data) {
    logProb <span class="pl-k">+=</span> bn<span class="pl-k">.</span>getLogProbabiltyOf(instance);
}
<span class="pl-smi">System</span><span class="pl-k">.</span>out<span class="pl-k">.</span>println(logProb);

<span class="pl-smi">BayesianNetworkWriter</span><span class="pl-k">.</span>saveToFile(bn, <span class="pl-s"><span class="pl-pds">"</span>networks/BNExample.bn<span class="pl-pds">"</span></span>);</pre></div>

<p><a href="#documentation">[Back to Top]</a></p>

<h3>
<a id="creating-bayesian-networks-with-latent-variables-" class="anchor" href="#creating-bayesian-networks-with-latent-variables-" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Creating Bayesian Networks with latent variables <a name="bnhiddenexample"></a>
</h3>

<p>In this example, we simply show how to create a BN model with hidden variables. We simply create a BN for clustering, i.e.,  a naive-Bayes like structure with a single common hidden variable acting as parant of all the observable variables.</p>

<div class="highlight highlight-source-java"><pre><span class="pl-c">//We can open the data stream using the static class DataStreamLoader</span>
<span class="pl-k">DataStream&lt;<span class="pl-smi">DataInstance</span>&gt;</span> data <span class="pl-k">=</span> <span class="pl-smi">DataStreamLoader</span><span class="pl-k">.</span>openFromFile(<span class="pl-s"><span class="pl-pds">"</span>datasets/syntheticData.arff<span class="pl-pds">"</span></span>);

<span class="pl-c">/**</span>
<span class="pl-c"> * 1. Once the data is loaded, we create a random variable for each of the attributes (i.e. data columns)</span>
<span class="pl-c"> * in our data.</span>
<span class="pl-c"> *</span>
<span class="pl-c"> * 2. {@link Variables} is the class for doing that. It takes a list of Attributes and internally creates</span>
<span class="pl-c"> * all the variables. We create the variables using Variables class to guarantee that each variable</span>
<span class="pl-c"> * has a different ID number and make it transparent for the user.</span>
<span class="pl-c"> *</span>
<span class="pl-c"> * 3. We can extract the Variable objects by using the method getVariableByName();</span>
<span class="pl-c"> */</span>
<span class="pl-smi">Variables</span> variables <span class="pl-k">=</span> <span class="pl-k">new</span> <span class="pl-smi">Variables</span>(data<span class="pl-k">.</span>getAttributes());

<span class="pl-smi">Variable</span> a <span class="pl-k">=</span> variables<span class="pl-k">.</span>getVariableByName(<span class="pl-s"><span class="pl-pds">"</span>A<span class="pl-pds">"</span></span>);
<span class="pl-smi">Variable</span> b <span class="pl-k">=</span> variables<span class="pl-k">.</span>getVariableByName(<span class="pl-s"><span class="pl-pds">"</span>B<span class="pl-pds">"</span></span>);
<span class="pl-smi">Variable</span> c <span class="pl-k">=</span> variables<span class="pl-k">.</span>getVariableByName(<span class="pl-s"><span class="pl-pds">"</span>C<span class="pl-pds">"</span></span>);
<span class="pl-smi">Variable</span> d <span class="pl-k">=</span> variables<span class="pl-k">.</span>getVariableByName(<span class="pl-s"><span class="pl-pds">"</span>D<span class="pl-pds">"</span></span>);
<span class="pl-smi">Variable</span> e <span class="pl-k">=</span> variables<span class="pl-k">.</span>getVariableByName(<span class="pl-s"><span class="pl-pds">"</span>E<span class="pl-pds">"</span></span>);
<span class="pl-smi">Variable</span> g <span class="pl-k">=</span> variables<span class="pl-k">.</span>getVariableByName(<span class="pl-s"><span class="pl-pds">"</span>G<span class="pl-pds">"</span></span>);
<span class="pl-smi">Variable</span> h <span class="pl-k">=</span> variables<span class="pl-k">.</span>getVariableByName(<span class="pl-s"><span class="pl-pds">"</span>H<span class="pl-pds">"</span></span>);
<span class="pl-smi">Variable</span> i <span class="pl-k">=</span> variables<span class="pl-k">.</span>getVariableByName(<span class="pl-s"><span class="pl-pds">"</span>I<span class="pl-pds">"</span></span>);

<span class="pl-c">/**</span>
<span class="pl-c"> * 1. We create the hidden variable. For doing that we make use of the method "newMultionomialVariable". When</span>
<span class="pl-c"> * a variable is created from an Attribute object, it contains all the information we need (e.g.</span>
<span class="pl-c"> * the name, the type, etc). But hidden variables does not have an associated attribute</span>
<span class="pl-c"> * and, for this reason, we use now this to provide this information.</span>
<span class="pl-c"> *</span>
<span class="pl-c"> * 2. Using the "newMultionomialVariable" method, we define a variable called HiddenVar, which is</span>
<span class="pl-c"> * not associated to any attribute and, then, it is a latent variable, its state space is a finite set with two elements, and its</span>
<span class="pl-c"> * distribution type is multinomial.</span>
<span class="pl-c"> *</span>
<span class="pl-c"> * 3. We finally create the hidden variable using the method "newVariable".</span>
<span class="pl-c"> */</span>

<span class="pl-smi">Variable</span> hidden <span class="pl-k">=</span> variables<span class="pl-k">.</span>newMultionomialVariable(<span class="pl-s"><span class="pl-pds">"</span>HiddenVar<span class="pl-pds">"</span></span>, <span class="pl-smi">Arrays</span><span class="pl-k">.</span>asList(<span class="pl-s"><span class="pl-pds">"</span>TRUE<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>FALSE<span class="pl-pds">"</span></span>));

<span class="pl-c">/**</span>
<span class="pl-c"> * 1. Once we have defined your {@link Variables} object, including the latent variable,</span>
<span class="pl-c"> * the next step is to create a DAG structure over this set of variables.</span>
<span class="pl-c"> *</span>
<span class="pl-c"> * 2. To add parents to each variable, we first recover the ParentSet object by the method</span>
<span class="pl-c"> * getParentSet(Variable var) and then call the method addParent(Variable var).</span>
<span class="pl-c"> *</span>
<span class="pl-c"> * 3. We just put the hidden variable as parent of all the other variables. Following a naive-Bayes</span>
<span class="pl-c"> * like structure.</span>
<span class="pl-c"> */</span>
<span class="pl-smi">DAG</span> dag <span class="pl-k">=</span> <span class="pl-k">new</span> <span class="pl-smi">DAG</span>(variables);

dag<span class="pl-k">.</span>getParentSet(a)<span class="pl-k">.</span>addParent(hidden);
dag<span class="pl-k">.</span>getParentSet(b)<span class="pl-k">.</span>addParent(hidden);
dag<span class="pl-k">.</span>getParentSet(c)<span class="pl-k">.</span>addParent(hidden);
dag<span class="pl-k">.</span>getParentSet(d)<span class="pl-k">.</span>addParent(hidden);
dag<span class="pl-k">.</span>getParentSet(e)<span class="pl-k">.</span>addParent(hidden);
dag<span class="pl-k">.</span>getParentSet(g)<span class="pl-k">.</span>addParent(hidden);
dag<span class="pl-k">.</span>getParentSet(h)<span class="pl-k">.</span>addParent(hidden);
dag<span class="pl-k">.</span>getParentSet(i)<span class="pl-k">.</span>addParent(hidden);

<span class="pl-c">/**</span>
<span class="pl-c"> * We print the graph to see if is properly created.</span>
<span class="pl-c"> */</span>
<span class="pl-smi">System</span><span class="pl-k">.</span>out<span class="pl-k">.</span>println(dag<span class="pl-k">.</span>toString());

<span class="pl-c">/**</span>
<span class="pl-c"> * 1. We now create the Bayesian network from the previous DAG.</span>
<span class="pl-c"> *</span>
<span class="pl-c"> * 2. The BN object is created from the DAG. It automatically looks at the distribution type</span>
<span class="pl-c"> * of each variable and their parents to initialize the Distributions objects that are stored</span>
<span class="pl-c"> * inside (i.e. Multinomial, Normal, CLG, etc). The parameters defining these distributions are</span>
<span class="pl-c"> * properly initialized.</span>
<span class="pl-c"> *</span>
<span class="pl-c"> * 3. The network is printed and we can have look at the kind of distributions stored in the BN object.</span>
<span class="pl-c"> */</span>
<span class="pl-smi">BayesianNetwork</span> bn <span class="pl-k">=</span> <span class="pl-k">new</span> <span class="pl-smi">BayesianNetwork</span>(dag);
<span class="pl-smi">System</span><span class="pl-k">.</span>out<span class="pl-k">.</span>println(bn<span class="pl-k">.</span>toString());

<span class="pl-c">/**</span>
<span class="pl-c"> * Finally teh Bayesian network is saved to a file.</span>
<span class="pl-c"> */</span>
<span class="pl-smi">BayesianNetworkWriter</span><span class="pl-k">.</span>saveToFile(bn, <span class="pl-s"><span class="pl-pds">"</span>networks/BNHiddenExample.bn<span class="pl-pds">"</span></span>);</pre></div>

<p><a href="#documentation">[Back to Top]</a></p>

<h3>
<a id="modifying-bayesian-networks-" class="anchor" href="#modifying-bayesian-networks-" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Modifying Bayesian Networks <a name="bnmodifyexample"></a>
</h3>

<p>In this example we show how to access and modify the conditional probabilities of a Bayesian network model.</p>

<div class="highlight highlight-source-java"><pre><span class="pl-c">//We first generate a Bayesian network with one multinomial, one Gaussian variable and one link.</span>
<span class="pl-smi">BayesianNetworkGenerator</span><span class="pl-k">.</span>setNumberOfGaussianVars(<span class="pl-c1">1</span>);
<span class="pl-smi">BayesianNetworkGenerator</span><span class="pl-k">.</span>setNumberOfMultinomialVars(<span class="pl-c1">1</span>,<span class="pl-c1">2</span>);
<span class="pl-smi">BayesianNetworkGenerator</span><span class="pl-k">.</span>setNumberOfLinks(<span class="pl-c1">1</span>);

<span class="pl-smi">BayesianNetwork</span> bn <span class="pl-k">=</span> <span class="pl-smi">BayesianNetworkGenerator</span><span class="pl-k">.</span>generateBayesianNetwork();

<span class="pl-c">//We print the randomly generated Bayesian networks</span>
<span class="pl-smi">System</span><span class="pl-k">.</span>out<span class="pl-k">.</span>println(bn<span class="pl-k">.</span>toString());

<span class="pl-c">//We first access the variable we are interested in</span>
<span class="pl-smi">Variable</span> multiVar <span class="pl-k">=</span> bn<span class="pl-k">.</span>getStaticVariables()<span class="pl-k">.</span>getVariableByName(<span class="pl-s"><span class="pl-pds">"</span>DiscreteVar0<span class="pl-pds">"</span></span>);

<span class="pl-c">//Using the above variable we can get the associated distribution and modify it</span>
<span class="pl-smi">Multinomial</span> multinomial <span class="pl-k">=</span> bn<span class="pl-k">.</span>getConditionalDistribution(multiVar);
multinomial<span class="pl-k">.</span>setProbabilities(<span class="pl-k">new</span> <span class="pl-smi">double</span>[]{<span class="pl-c1">0.2</span>, <span class="pl-c1">0.8</span>});

<span class="pl-c">//Same than before but accessing the another variable</span>
<span class="pl-smi">Variable</span> normalVar <span class="pl-k">=</span> bn<span class="pl-k">.</span>getStaticVariables()<span class="pl-k">.</span>getVariableByName(<span class="pl-s"><span class="pl-pds">"</span>GaussianVar0<span class="pl-pds">"</span></span>);

<span class="pl-c">//In this case, the conditional distribtuion is of the type "Normal given Multinomial Parents"</span>
<span class="pl-smi">Normal_MultinomialParents</span> normalMultiDist <span class="pl-k">=</span> bn<span class="pl-k">.</span>getConditionalDistribution(normalVar);
normalMultiDist<span class="pl-k">.</span>getNormal(<span class="pl-c1">0</span>)<span class="pl-k">.</span>setMean(<span class="pl-c1">1.0</span>);
normalMultiDist<span class="pl-k">.</span>getNormal(<span class="pl-c1">0</span>)<span class="pl-k">.</span>setVariance(<span class="pl-c1">1.0</span>);

normalMultiDist<span class="pl-k">.</span>getNormal(<span class="pl-c1">1</span>)<span class="pl-k">.</span>setMean(<span class="pl-c1">0.0</span>);
normalMultiDist<span class="pl-k">.</span>getNormal(<span class="pl-c1">1</span>)<span class="pl-k">.</span>setVariance(<span class="pl-c1">1.0</span>);

<span class="pl-c">//We print modified Bayesian network</span>
<span class="pl-smi">System</span><span class="pl-k">.</span>out<span class="pl-k">.</span>println(bn<span class="pl-k">.</span>toString());</pre></div>

<p><a href="#documentation">[Back to Top]</a></p>

<h2>
<a id="io-functionality-" class="anchor" href="#io-functionality-" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>I/O Functionality <a name="ioexample"></a>
</h2>

<h3>
<a id="io-of-data-streams-" class="anchor" href="#io-of-data-streams-" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>I/O of Data Streams <a name="iodatastreamsexample"></a>
</h3>

<p>In this example we show how to load and save data sets from <a href="http://www.cs.waikato.ac.nz/ml/weka/arff.html">.arff</a> files. </p>

<div class="highlight highlight-source-java"><pre><span class="pl-c">//We can open the data stream using the static class DataStreamLoader</span>
<span class="pl-k">DataStream&lt;<span class="pl-smi">DataInstance</span>&gt;</span> data <span class="pl-k">=</span> <span class="pl-smi">DataStreamLoader</span><span class="pl-k">.</span>openFromFile(<span class="pl-s"><span class="pl-pds">"</span>datasets/syntheticData.arff<span class="pl-pds">"</span></span>);

<span class="pl-c">//We can save this data set to a new file using the static class DataStreamWriter</span>
<span class="pl-smi">DataStreamWriter</span><span class="pl-k">.</span>writeDataToFile(data, <span class="pl-s"><span class="pl-pds">"</span>datasets/tmp.arff<span class="pl-pds">"</span></span>);</pre></div>

<p><a href="#documentation">[Back to Top]</a></p>

<h3>
<a id="io-of-bayesian-networks-" class="anchor" href="#io-of-bayesian-networks-" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>I/O of Bayesian Networks <a name="iobnsexample"></a>
</h3>

<p>In this example we show how to load and save Bayesian networks models for a binary file with ".bn" extension. In this toolbox Bayesian networks models are saved as serialized objects.</p>

<div class="highlight highlight-source-java"><pre><span class="pl-c">//We can load a Bayesian network using the static class BayesianNetworkLoader</span>
<span class="pl-smi">BayesianNetwork</span> bn <span class="pl-k">=</span> <span class="pl-smi">BayesianNetworkLoader</span><span class="pl-k">.</span>loadFromFile(<span class="pl-s"><span class="pl-pds">"</span>./networks/WasteIncinerator.bn<span class="pl-pds">"</span></span>);

<span class="pl-c">//Now we print the loaded model</span>
<span class="pl-smi">System</span><span class="pl-k">.</span>out<span class="pl-k">.</span>println(bn<span class="pl-k">.</span>toString());

<span class="pl-c">//Now we change the parameters of the model</span>
bn<span class="pl-k">.</span>randomInitialization(<span class="pl-k">new</span> <span class="pl-smi">Random</span>(<span class="pl-c1">0</span>));

<span class="pl-c">//We can save this Bayesian network to using the static class BayesianNetworkWriter</span>
<span class="pl-smi">BayesianNetworkWriter</span><span class="pl-k">.</span>saveToFile(bn, <span class="pl-s"><span class="pl-pds">"</span>networks/tmp.bn<span class="pl-pds">"</span></span>);</pre></div>

<p><a href="#documentation">[Back to Top]</a></p>

<h2>
<a id="inference-algorithms-" class="anchor" href="#inference-algorithms-" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Inference Algorithms <a name="inferenceexample"></a>
</h2>

<h3>
<a id="the-inference-engine-" class="anchor" href="#the-inference-engine-" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>The Inference Engine <a name="inferenceengingeexample"></a>
</h3>

<p>This example show how to perform inference in a Bayesian network model using the InferenceEngine static class. This class aims to be a straigthfoward way to perform queries over a Bayesian network model. By the default the \textit{VMP} inference method is invoked.</p>

<div class="highlight highlight-source-java"><pre><span class="pl-c">//We first load the WasteIncinerator bayesian network which has multinomial </span>
<span class="pl-c">//and Gaussian variables.</span>
<span class="pl-smi">BayesianNetwork</span> bn <span class="pl-k">=</span> <span class="pl-smi">BayesianNetworkLoader</span><span class="pl-k">.</span>loadFromFile(<span class="pl-s"><span class="pl-pds">"</span>./networks/WasteIncinerator.bn<span class="pl-pds">"</span></span>);

<span class="pl-c">//We recover the relevant variables for this example: Mout which is normally </span>
<span class="pl-c">//distributed, and W which is multinomial.</span>
<span class="pl-smi">Variable</span> varMout <span class="pl-k">=</span> bn<span class="pl-k">.</span>getStaticVariables()<span class="pl-k">.</span>getVariableByName(<span class="pl-s"><span class="pl-pds">"</span>Mout<span class="pl-pds">"</span></span>);
<span class="pl-smi">Variable</span> varW <span class="pl-k">=</span> bn<span class="pl-k">.</span>getStaticVariables()<span class="pl-k">.</span>getVariableByName(<span class="pl-s"><span class="pl-pds">"</span>W<span class="pl-pds">"</span></span>);

<span class="pl-c">//Set the evidence.</span>
<span class="pl-smi">Assignment</span> assignment <span class="pl-k">=</span> <span class="pl-k">new</span> <span class="pl-smi">HashMapAssignment</span>(<span class="pl-c1">1</span>);
assignment<span class="pl-k">.</span>setValue(varW,<span class="pl-c1">0</span>);

<span class="pl-c">//Then we query the posterior of</span>
<span class="pl-smi">System</span><span class="pl-k">.</span>out<span class="pl-k">.</span>println(<span class="pl-s"><span class="pl-pds">"</span>P(Mout|W=0) = <span class="pl-pds">"</span></span> <span class="pl-k">+</span> <span class="pl-smi">InferenceEngine</span><span class="pl-k">.</span>getPosterior(varMout, bn, assignment));

<span class="pl-c">//Or some more refined queries</span>
<span class="pl-smi">System</span><span class="pl-k">.</span>out<span class="pl-k">.</span>println(<span class="pl-s"><span class="pl-pds">"</span>P(0.7&lt;Mout&lt;6.59 | W=0) = <span class="pl-pds">"</span></span> <span class="pl-k">+</span> 
 <span class="pl-smi">InferenceEngine</span><span class="pl-k">.</span>getExpectedValue(varMout, bn, v <span class="pl-k">-</span><span class="pl-k">&gt;</span> (<span class="pl-c1">0.7</span> <span class="pl-k">&lt;</span> v <span class="pl-k">&amp;&amp;</span> v <span class="pl-k">&lt;</span> <span class="pl-c1">6.59</span>) <span class="pl-k">?</span> <span class="pl-c1">1.0</span> <span class="pl-k">:</span> <span class="pl-c1">0.0</span> ));</pre></div>

<p><a href="#documentation">[Back to Top]</a></p>

<h3>
<a id="variational-message-passing-" class="anchor" href="#variational-message-passing-" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Variational Message Passing <a name="vmpexample"></a>
</h3>

<p>This example we show how to perform inference on a general Bayesian network using the Variational Message Passing (VMP)
algorithm detailed in</p>

<blockquote>
<p>Winn, J. M., Bishop, C. M. (2005). Variational message passing. In Journal of Machine Learning Research (pp. 661-694).</p>
</blockquote>

<div class="highlight highlight-source-java"><pre><span class="pl-c">//We first load the WasteIncinerator bayesian network which has multinomial </span>
<span class="pl-c">//and Gaussian variables.</span>
<span class="pl-smi">BayesianNetwork</span> bn <span class="pl-k">=</span> <span class="pl-smi">BayesianNetworkLoader</span><span class="pl-k">.</span>loadFromFile(<span class="pl-s"><span class="pl-pds">"</span>./networks/WasteIncinerator.bn<span class="pl-pds">"</span></span>);

<span class="pl-c">//We recover the relevant variables for this example: Mout which is normally </span>
<span class="pl-c">//distributed, and W which is multinomial.</span>
<span class="pl-smi">Variable</span> varMout <span class="pl-k">=</span> bn<span class="pl-k">.</span>getStaticVariables()<span class="pl-k">.</span>getVariableByName(<span class="pl-s"><span class="pl-pds">"</span>Mout<span class="pl-pds">"</span></span>);
<span class="pl-smi">Variable</span> varW <span class="pl-k">=</span> bn<span class="pl-k">.</span>getStaticVariables()<span class="pl-k">.</span>getVariableByName(<span class="pl-s"><span class="pl-pds">"</span>W<span class="pl-pds">"</span></span>);

<span class="pl-c">//First we create an instance of a inference algorithm. In this case, we use </span>
<span class="pl-c">//the VMP class.</span>
<span class="pl-smi">InferenceAlgorithm</span> inferenceAlgorithm <span class="pl-k">=</span> <span class="pl-k">new</span> <span class="pl-smi">VMP</span>();

<span class="pl-c">//Then, we set the BN model</span>
inferenceAlgorithm<span class="pl-k">.</span>setModel(bn);

<span class="pl-c">//If exists, we also set the evidence.</span>
<span class="pl-smi">Assignment</span> assignment <span class="pl-k">=</span> <span class="pl-k">new</span> <span class="pl-smi">HashMapAssignment</span>(<span class="pl-c1">1</span>);
assignment<span class="pl-k">.</span>setValue(varW,<span class="pl-c1">0</span>);
inferenceAlgorithm<span class="pl-k">.</span>setEvidence(assignment);

<span class="pl-c">//Then we run inference</span>
inferenceAlgorithm<span class="pl-k">.</span>runInference();

<span class="pl-c">//Then we query the posterior of</span>
<span class="pl-smi">System</span><span class="pl-k">.</span>out<span class="pl-k">.</span>println(<span class="pl-s"><span class="pl-pds">"</span>P(Mout|W=0) = <span class="pl-pds">"</span></span> <span class="pl-k">+</span> inferenceAlgorithm<span class="pl-k">.</span>getPosterior(varMout));

<span class="pl-c">//Or some more refined queries</span>
<span class="pl-smi">System</span><span class="pl-k">.</span>out<span class="pl-k">.</span>println(<span class="pl-s"><span class="pl-pds">"</span>P(0.7&lt;Mout&lt;6.59 | W=0) = <span class="pl-pds">"</span></span> <span class="pl-k">+</span> 
 inferenceAlgorithm<span class="pl-k">.</span>getExpectedValue(varMout, v <span class="pl-k">-</span><span class="pl-k">&gt;</span> (<span class="pl-c1">0.7</span> <span class="pl-k">&lt;</span> v <span class="pl-k">&amp;&amp;</span> v <span class="pl-k">&lt;</span> <span class="pl-c1">6.59</span>) <span class="pl-k">?</span> <span class="pl-c1">1.0</span> <span class="pl-k">:</span> <span class="pl-c1">0.0</span> ));

<span class="pl-c">//We can also compute the probability of the evidence</span>
<span class="pl-smi">System</span><span class="pl-k">.</span>out<span class="pl-k">.</span>println(<span class="pl-s"><span class="pl-pds">"</span>P(W=0) = <span class="pl-pds">"</span></span> <span class="pl-k">+</span> <span class="pl-smi">Math</span><span class="pl-k">.</span>exp(inferenceAlgorithm<span class="pl-k">.</span>getLogProbabilityOfEvidence()));</pre></div>

<p><a href="#documentation">[Back to Top]</a></p>

<h3>
<a id="importance-sampling-" class="anchor" href="#importance-sampling-" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Importance Sampling <a name="isexample"></a>
</h3>

<p>This example we show how to perform inference on a general Bayesian network using an importance sampling
algorithm detailed in</p>

<blockquote>
<p>Fung, R., Chang, K. C. (2013). Weighing and integrating evidence for stochastic simulation in Bayesian networks. arXiv preprint arXiv:1304.1504.</p>
</blockquote>

<div class="highlight highlight-source-java"><pre><span class="pl-c">//We first load the WasteIncinerator bayesian network which has multinomial </span>
<span class="pl-c">//and Gaussian variables.</span>
<span class="pl-smi">BayesianNetwork</span> bn <span class="pl-k">=</span> <span class="pl-smi">BayesianNetworkLoader</span><span class="pl-k">.</span>loadFromFile(<span class="pl-s"><span class="pl-pds">"</span>./networks/WasteIncinerator.bn<span class="pl-pds">"</span></span>);

<span class="pl-c">//We recover the relevant variables for this example: Mout which is normally </span>
<span class="pl-c">//distributed, and W which is multinomial.</span>
<span class="pl-smi">Variable</span> varMout <span class="pl-k">=</span> bn<span class="pl-k">.</span>getStaticVariables()<span class="pl-k">.</span>getVariableByName(<span class="pl-s"><span class="pl-pds">"</span>Mout<span class="pl-pds">"</span></span>);
<span class="pl-smi">Variable</span> varW <span class="pl-k">=</span> bn<span class="pl-k">.</span>getStaticVariables()<span class="pl-k">.</span>getVariableByName(<span class="pl-s"><span class="pl-pds">"</span>W<span class="pl-pds">"</span></span>);

<span class="pl-c">//First we create an instance of a inference algorithm. In this case, we use </span>
<span class="pl-c">//the ImportanceSampling class.</span>
<span class="pl-smi">InferenceAlgorithm</span> inferenceAlgorithm <span class="pl-k">=</span> <span class="pl-k">new</span> <span class="pl-smi">ImportanceSampling</span>();

<span class="pl-c">//Then, we set the BN model</span>
inferenceAlgorithm<span class="pl-k">.</span>setModel(bn);

<span class="pl-c">//If exists, we also set the evidence.</span>
<span class="pl-smi">Assignment</span> assignment <span class="pl-k">=</span> <span class="pl-k">new</span> <span class="pl-smi">HashMapAssignment</span>(<span class="pl-c1">1</span>);
assignment<span class="pl-k">.</span>setValue(varW,<span class="pl-c1">0</span>);
inferenceAlgorithm<span class="pl-k">.</span>setEvidence(assignment);

<span class="pl-c">//We can also set to be run in parallel on multicore CPUs</span>
inferenceAlgorithm<span class="pl-k">.</span>setParallelMode(<span class="pl-c1">true</span>);

<span class="pl-c">//Then we run inference</span>
inferenceAlgorithm<span class="pl-k">.</span>runInference();

<span class="pl-c">//Then we query the posterior of</span>
<span class="pl-smi">System</span><span class="pl-k">.</span>out<span class="pl-k">.</span>println(<span class="pl-s"><span class="pl-pds">"</span>P(Mout|W=0) = <span class="pl-pds">"</span></span> <span class="pl-k">+</span> inferenceAlgorithm<span class="pl-k">.</span>getPosterior(varMout));

<span class="pl-c">//Or some more refined queries</span>
<span class="pl-smi">System</span><span class="pl-k">.</span>out<span class="pl-k">.</span>println(<span class="pl-s"><span class="pl-pds">"</span>P(0.7&lt;Mout&lt;6.59 | W=0) = <span class="pl-pds">"</span></span> <span class="pl-k">+</span> 
 inferenceAlgorithm<span class="pl-k">.</span>getExpectedValue(varMout, v <span class="pl-k">-</span><span class="pl-k">&gt;</span> (<span class="pl-c1">0.7</span> <span class="pl-k">&lt;</span> v <span class="pl-k">&amp;&amp;</span> v <span class="pl-k">&lt;</span> <span class="pl-c1">6.59</span>) <span class="pl-k">?</span> <span class="pl-c1">1.0</span> <span class="pl-k">:</span> <span class="pl-c1">0.0</span> ));

<span class="pl-c">//We can also compute the probability of the evidence</span>
<span class="pl-smi">System</span><span class="pl-k">.</span>out<span class="pl-k">.</span>println(<span class="pl-s"><span class="pl-pds">"</span>P(W=0) = <span class="pl-pds">"</span></span> <span class="pl-k">+</span> <span class="pl-smi">Math</span><span class="pl-k">.</span>exp(inferenceAlgorithm<span class="pl-k">.</span>getLogProbabilityOfEvidence()));</pre></div>

<p><a href="#documentation">[Back to Top]</a></p>

<h2>
<a id="learning-algorithms-" class="anchor" href="#learning-algorithms-" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Learning Algorithms <a name="learningexample"></a>
</h2>

<h3>
<a id="maximum-likelihood-" class="anchor" href="#maximum-likelihood-" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Maximum Likelihood <a name="mlexample"></a>
</h3>

<p>This other example shows how to learn incrementally the parameters of a Bayesian network using data batches,</p>

<div class="highlight highlight-source-java"><pre><span class="pl-c">//We can open the data stream using the static class DataStreamLoader</span>
<span class="pl-k">DataStream&lt;<span class="pl-smi">DataInstance</span>&gt;</span> data <span class="pl-k">=</span> 
                  <span class="pl-smi">DataStreamLoader</span><span class="pl-k">.</span>openFromFile(<span class="pl-s"><span class="pl-pds">"</span>datasets/WasteIncineratorSample.arff<span class="pl-pds">"</span></span>);

<span class="pl-c">//We create a ParameterLearningAlgorithm object with the MaximumLikehood builder</span>
<span class="pl-smi">ParameterLearningAlgorithm</span> parameterLearningAlgorithm <span class="pl-k">=</span> <span class="pl-k">new</span> <span class="pl-smi">ParallelMaximumLikelihood</span>();

<span class="pl-c">//We fix the DAG structure</span>
parameterLearningAlgorithm<span class="pl-k">.</span>setDAG(getNaiveBayesStructure(data,<span class="pl-c1">0</span>));

<span class="pl-c">//We should invoke this method before processing any data</span>
parameterLearningAlgorithm<span class="pl-k">.</span>initLearning();


<span class="pl-c">//Then we show how we can perform parameter learnig by a sequential updating of data batches.</span>
<span class="pl-k">for</span> (<span class="pl-k">DataOnMemory&lt;<span class="pl-smi">DataInstance</span>&gt;</span> batch <span class="pl-k">:</span> data<span class="pl-k">.</span>iterableOverBatches(<span class="pl-c1">100</span>)){
    parameterLearningAlgorithm<span class="pl-k">.</span>updateModel(batch);
}

<span class="pl-c">//And we get the model</span>
<span class="pl-smi">BayesianNetwork</span> bnModel <span class="pl-k">=</span> parameterLearningAlgorithm<span class="pl-k">.</span>getLearntBayesianNetwork();

<span class="pl-c">//We print the model</span>
<span class="pl-smi">System</span><span class="pl-k">.</span>out<span class="pl-k">.</span>println(bnModel<span class="pl-k">.</span>toString());</pre></div>

<p><a href="#documentation">[Back to Top]</a></p>

<h3>
<a id="parallel-maximum-likelihood-" class="anchor" href="#parallel-maximum-likelihood-" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Parallel Maximum Likelihood <a name="pmlexample"></a>
</h3>

<p>This example shows how to learn in parallel the parameters of a Bayesian network from a stream of data using maximum likelihood.</p>

<div class="highlight highlight-source-java"><pre><span class="pl-c">//We can open the data stream using the static class DataStreamLoader</span>
<span class="pl-k">DataStream&lt;<span class="pl-smi">DataInstance</span>&gt;</span> data <span class="pl-k">=</span> 
           <span class="pl-smi">DataStreamLoader</span><span class="pl-k">.</span>openFromFile(<span class="pl-s"><span class="pl-pds">"</span>datasets/syntheticData.arff<span class="pl-pds">"</span></span>);

<span class="pl-c">//We create a MaximumLikelihood object with the MaximumLikehood builder</span>
<span class="pl-smi">MaximumLikelihood</span> parameterLearningAlgorithm <span class="pl-k">=</span> <span class="pl-k">new</span> <span class="pl-smi">MaximumLikelihood</span>();

<span class="pl-c">//We activate the parallel mode.</span>
parameterLearningAlgorithm<span class="pl-k">.</span>setParallelMode(<span class="pl-c1">true</span>);

<span class="pl-c">//We fix the DAG structure</span>
parameterLearningAlgorithm<span class="pl-k">.</span>setDAG(getNaiveBayesStructure(data,<span class="pl-c1">0</span>));

<span class="pl-c">//We set the batch size which will be employed to learn the model in parallel</span>
parameterLearningAlgorithm<span class="pl-k">.</span>setBatchSize(<span class="pl-c1">100</span>);

<span class="pl-c">//We set the data which is going to be used for leaning the parameters</span>
parameterLearningAlgorithm<span class="pl-k">.</span>setDataStream(data);

<span class="pl-c">//We perform the learning</span>
parameterLearningAlgorithm<span class="pl-k">.</span>runLearning();

<span class="pl-c">//And we get the model</span>
<span class="pl-smi">BayesianNetwork</span> bnModel <span class="pl-k">=</span> parameterLearningAlgorithm<span class="pl-k">.</span>getLearntBayesianNetwork();

<span class="pl-c">//We print the model</span>
<span class="pl-smi">System</span><span class="pl-k">.</span>out<span class="pl-k">.</span>println(bnModel<span class="pl-k">.</span>toString());</pre></div>

<p><a href="#documentation">[Back to Top]</a></p>

<h3>
<a id="streaming-variational-bayes-" class="anchor" href="#streaming-variational-bayes-" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Streaming Variational Bayes <a name="svbexample"></a>
</h3>

<p>This example shows how to learn incrementally the parameters of a Bayesian network from a stream of data with a Bayesian approach using the following algorithm,</p>

<blockquote>
<p>Broderick, T., Boyd, N., Wibisono, A., Wilson, A. C., &amp; Jordan, M. I. (2013). Streaming variational Bayes. 
In Advances in Neural Information Processing Systems (pp. 1727-1735).</p>
</blockquote>

<p>In this second example we show a alternative implementation which explicitly updates the model by batches by using the class <em>SVB</em>.</p>

<div class="highlight highlight-source-java"><pre><span class="pl-c">//We can open the data stream using the static class DataStreamLoader</span>
<span class="pl-k">DataStream&lt;<span class="pl-smi">DataInstance</span>&gt;</span> data <span class="pl-k">=</span> 
                      <span class="pl-smi">DataStreamLoader</span><span class="pl-k">.</span>openFromFile(<span class="pl-s"><span class="pl-pds">"</span>datasets/WasteIncineratorSample.arff<span class="pl-pds">"</span></span>);

<span class="pl-c">//We create a StreamingVariationalBayesVMP object</span>
<span class="pl-smi">StreamingVariationalBayesVMP</span> parameterLearningAlgorithm <span class="pl-k">=</span> <span class="pl-k">new</span> <span class="pl-smi">StreamingVariationalBayesVMP</span>();

<span class="pl-c">//We fix the DAG structure, which is a Naive Bayes with a </span>
<span class="pl-c">//global latent binary variable</span>
parameterLearningAlgorithm<span class="pl-k">.</span>setDAG(getHiddenNaiveBayesStructure(data));

<span class="pl-c">//We fix the size of the window, which must be equal to the size of the data batches </span>
<span class="pl-c">//we use for learning</span>
parameterLearningAlgorithm<span class="pl-k">.</span>setWindowsSize(<span class="pl-c1">5</span>);

<span class="pl-c">//We can activate the output</span>
parameterLearningAlgorithm<span class="pl-k">.</span>setOutput(<span class="pl-c1">true</span>);

<span class="pl-c">//We should invoke this method before processing any data</span>
parameterLearningAlgorithm<span class="pl-k">.</span>initLearning();

<span class="pl-c">//Then we show how we can perform parameter learnig by a sequential updating of </span>
<span class="pl-c">//data batches.</span>
<span class="pl-k">for</span> (<span class="pl-k">DataOnMemory&lt;<span class="pl-smi">DataInstance</span>&gt;</span> batch <span class="pl-k">:</span> data<span class="pl-k">.</span>iterableOverBatches(<span class="pl-c1">5</span>)){
    parameterLearningAlgorithm<span class="pl-k">.</span>updateModel(batch);
}

<span class="pl-c">//And we get the model</span>
<span class="pl-smi">BayesianNetwork</span> bnModel <span class="pl-k">=</span> parameterLearningAlgorithm<span class="pl-k">.</span>getLearntBayesianNetwork();

<span class="pl-c">//We print the model</span>
<span class="pl-smi">System</span><span class="pl-k">.</span>out<span class="pl-k">.</span>println(bnModel<span class="pl-k">.</span>toString());</pre></div>

<p><a href="#documentation">[Back to Top]</a></p>

<h3>
<a id="parallel-streaming-variational-bayes-" class="anchor" href="#parallel-streaming-variational-bayes-" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Parallel Streaming Variational Bayes <a name="psvbexample"></a>
</h3>

<p>This example shows how to learn in the parameters of a Bayesian network from a stream of data with a Bayesian
approach using the parallel version  of the SVB algorithm, </p>

<blockquote>
<p>Broderick, T., Boyd, N., Wibisono, A., Wilson, A. C., &amp; Jordan, M. I. (2013). Streaming variational Bayes. 
In Advances in Neural Information Processing Systems (pp. 1727-1735).</p>
</blockquote>

<div class="highlight highlight-source-java"><pre><span class="pl-c">//We can open the data stream using the static class DataStreamLoader</span>
<span class="pl-k">DataStream&lt;<span class="pl-smi">DataInstance</span>&gt;</span> data <span class="pl-k">=</span> 
                   <span class="pl-smi">DataStreamLoader</span><span class="pl-k">.</span>openFromFile(<span class="pl-s"><span class="pl-pds">"</span>datasets/WasteIncineratorSample.arff<span class="pl-pds">"</span></span>);

<span class="pl-c">//We create a ParallelSVB object</span>
<span class="pl-smi">ParallelSVB</span> parameterLearningAlgorithm <span class="pl-k">=</span> <span class="pl-k">new</span> <span class="pl-smi">ParallelSVB</span>();

<span class="pl-c">//We fix the number of cores we want to exploit</span>
parameterLearningAlgorithm<span class="pl-k">.</span>setNCores(<span class="pl-c1">4</span>);

<span class="pl-c">//We fix the DAG structure, which is a Naive Bayes with a </span>
<span class="pl-c">//global latent binary variable</span>
parameterLearningAlgorithm<span class="pl-k">.</span>setDAG(<span class="pl-smi">StreamingVMPExample</span><span class="pl-k">.</span>getHiddenNaiveBayesStructure(data));


<span class="pl-c">//We fix the size of the window</span>
parameterLearningAlgorithm<span class="pl-k">.</span>getSVBEngine()<span class="pl-k">.</span>setWindowsSize(<span class="pl-c1">100</span>);

<span class="pl-c">//We can activate the output</span>
parameterLearningAlgorithm<span class="pl-k">.</span>setOutput(<span class="pl-c1">true</span>);

<span class="pl-c">//We set the data which is going to be used for leaning the parameters</span>
parameterLearningAlgorithm<span class="pl-k">.</span>setDataStream(data);

<span class="pl-c">//We perform the learning</span>
parameterLearningAlgorithm<span class="pl-k">.</span>runLearning();

<span class="pl-c">//And we get the model</span>
<span class="pl-smi">BayesianNetwork</span> bnModel <span class="pl-k">=</span> parameterLearningAlgorithm<span class="pl-k">.</span>getLearntBayesianNetwork();

<span class="pl-c">//We print the model</span>
<span class="pl-smi">System</span><span class="pl-k">.</span>out<span class="pl-k">.</span>println(bnModel<span class="pl-k">.</span>toString());</pre></div>

<p><a href="#documentation">[Back to Top]</a></p>

<h2>
<a id="concept-drift-methods-" class="anchor" href="#concept-drift-methods-" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Concept Drift Methods <a name="conceptdriftexample"></a>
</h2>



<h3>
<a id="naive-bayes-with-virtual-concept-drift-detection-" class="anchor" href="#naive-bayes-with-virtual-concept-drift-detection-" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Naive Bayes with Virtual Concept Drift Detection <a name="nbconceptdriftexample"></a>
</h3>

<p>This example shows how to use the class NaiveBayesVirtualConceptDriftDetector to run the virtual concept drift detector detailed in</p>

<blockquote>
<p>Borchani et al. Modeling concept drift: A probabilistic graphical model based approach. IDA 2015.</p>
</blockquote>

<div class="highlight highlight-source-java"><pre><span class="pl-c">//We can open the data stream using the static class DataStreamLoader</span>
<span class="pl-k">DataStream&lt;<span class="pl-smi">DataInstance</span>&gt;</span> data <span class="pl-k">=</span> <span class="pl-smi">DataStreamLoader</span><span class="pl-k">.</span>openFromFile(<span class="pl-s"><span class="pl-pds">"</span>./datasets/DriftSets/sea.arff<span class="pl-pds">"</span></span>);

<span class="pl-c">//We create a NaiveBayesVirtualConceptDriftDetector object</span>
<span class="pl-smi">NaiveBayesVirtualConceptDriftDetector</span> virtualDriftDetector <span class="pl-k">=</span> 
                                        <span class="pl-k">new</span> <span class="pl-smi">NaiveBayesVirtualConceptDriftDetector</span>();

<span class="pl-c">//We set class variable as the last attribute</span>
virtualDriftDetector<span class="pl-k">.</span>setClassIndex(<span class="pl-k">-</span><span class="pl-c1">1</span>);

<span class="pl-c">//We set the data which is going to be used</span>
virtualDriftDetector<span class="pl-k">.</span>setData(data);

<span class="pl-c">//We fix the size of the window</span>
<span class="pl-k">int</span> windowSize <span class="pl-k">=</span> <span class="pl-c1">1000</span>;
virtualDriftDetector<span class="pl-k">.</span>setWindowsSize(windowSize);

<span class="pl-c">//We fix the so-called transition variance</span>
virtualDriftDetector<span class="pl-k">.</span>setTransitionVariance(<span class="pl-c1">0.1</span>);

<span class="pl-c">//We fix the number of global latent variables</span>
virtualDriftDetector<span class="pl-k">.</span>setNumberOfGlobalVars(<span class="pl-c1">1</span>);

<span class="pl-c">//We should invoke this method before processing any data</span>
virtualDriftDetector<span class="pl-k">.</span>initLearning();

<span class="pl-c">//Some prints</span>
<span class="pl-smi">System</span><span class="pl-k">.</span>out<span class="pl-k">.</span>print(<span class="pl-s"><span class="pl-pds">"</span>Batch<span class="pl-pds">"</span></span>);
<span class="pl-k">for</span> (<span class="pl-smi">Variable</span> hiddenVar <span class="pl-k">:</span> virtualDriftDetector<span class="pl-k">.</span>getHiddenVars()) {
    <span class="pl-smi">System</span><span class="pl-k">.</span>out<span class="pl-k">.</span>print(<span class="pl-s"><span class="pl-pds">"</span><span class="pl-cce">\t</span><span class="pl-pds">"</span></span> <span class="pl-k">+</span> hiddenVar<span class="pl-k">.</span>getName());
}
<span class="pl-smi">System</span><span class="pl-k">.</span>out<span class="pl-k">.</span>println();


<span class="pl-c">//Then we show how we can perform the sequential processing of</span>
<span class="pl-c">// data batches. They must be of the same value than the window</span>
<span class="pl-c">// size parameter set above.</span>
<span class="pl-k">int</span> countBatch <span class="pl-k">=</span> <span class="pl-c1">0</span>;
<span class="pl-k">for</span> (<span class="pl-k">DataOnMemory&lt;<span class="pl-smi">DataInstance</span>&gt;</span> batch <span class="pl-k">:</span> 
                data<span class="pl-k">.</span>iterableOverBatches(windowSize)){

    <span class="pl-c">//We update the model by invoking this method. The output</span>
    <span class="pl-c">// is an array with a value associated</span>
    <span class="pl-c">// to each fo the global hidden variables</span>
    <span class="pl-k">double</span>[] out <span class="pl-k">=</span> virtualDriftDetector<span class="pl-k">.</span>updateModel(batch);

    <span class="pl-c">//We print the output</span>
    <span class="pl-smi">System</span><span class="pl-k">.</span>out<span class="pl-k">.</span>print(countBatch <span class="pl-k">+</span> <span class="pl-s"><span class="pl-pds">"</span><span class="pl-cce">\t</span><span class="pl-pds">"</span></span>);
    <span class="pl-k">for</span> (<span class="pl-k">int</span> i <span class="pl-k">=</span> <span class="pl-c1">0</span>; i <span class="pl-k">&lt;</span> out<span class="pl-k">.</span>length; i<span class="pl-k">++</span>) {
        <span class="pl-smi">System</span><span class="pl-k">.</span>out<span class="pl-k">.</span>print(out[i]<span class="pl-k">+</span><span class="pl-s"><span class="pl-pds">"</span><span class="pl-cce">\t</span><span class="pl-pds">"</span></span>);
    }
    <span class="pl-smi">System</span><span class="pl-k">.</span>out<span class="pl-k">.</span>println();
    countBatch<span class="pl-k">++</span>;
}</pre></div>

<p><a href="#documentation">[Back to Top]</a></p>

<h2>
<a id="huginlink-" class="anchor" href="#huginlink-" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>HuginLink <a name="huginglinkexample"></a>
</h2>

<h3>
<a id="models-conversion-between-amidst-and-hugin-" class="anchor" href="#models-conversion-between-amidst-and-hugin-" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Models conversion between AMIDST and Hugin <a name="huginglinkconversionexample"></a>
</h3>

<p>This example shows how to use the class BNConverterToAMIDST and BNConverterToHugin to convert a 
Bayesian network models between Hugin and AMIDST formats</p>

<div class="highlight highlight-source-java"><pre><span class="pl-c">//We load from Hugin format</span>
<span class="pl-smi">Domain</span> huginBN <span class="pl-k">=</span> <span class="pl-smi">BNLoaderFromHugin</span><span class="pl-k">.</span>loadFromFile(<span class="pl-s"><span class="pl-pds">"</span>networks/asia.net<span class="pl-pds">"</span></span>);

<span class="pl-c">//Then, it is converted to AMIDST BayesianNetwork object</span>
<span class="pl-smi">BayesianNetwork</span> amidstBN <span class="pl-k">=</span> <span class="pl-smi">BNConverterToAMIDST</span><span class="pl-k">.</span>convertToAmidst(huginBN);

<span class="pl-c">//Then, it is converted to Hugin Bayesian Network object</span>
huginBN <span class="pl-k">=</span> <span class="pl-smi">BNConverterToHugin</span><span class="pl-k">.</span>convertToHugin(amidstBN);

<span class="pl-smi">System</span><span class="pl-k">.</span>out<span class="pl-k">.</span>println(amidstBN<span class="pl-k">.</span>toString());
<span class="pl-smi">System</span><span class="pl-k">.</span>out<span class="pl-k">.</span>println(huginBN<span class="pl-k">.</span>toString());</pre></div>

<p><a href="#documentation">[Back to Top]</a></p>

<h3>
<a id="io-of-bayesian-networks-with-hugin-net-format-" class="anchor" href="#io-of-bayesian-networks-with-hugin-net-format-" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>I/O of Bayesian Networks with Hugin net format <a name="huginglinkioexample"></a>
</h3>

<p>This example shows how to use the class BNLoaderFromHugin and BNWriterToHugin classes to load and
write Bayesian networks in Hugin format.</p>

<div class="highlight highlight-source-java"><pre><span class="pl-c">//We load from Hugin format</span>
<span class="pl-smi">Domain</span> huginBN <span class="pl-k">=</span> <span class="pl-smi">BNLoaderFromHugin</span><span class="pl-k">.</span>loadFromFile(<span class="pl-s"><span class="pl-pds">"</span>networks/asia.net<span class="pl-pds">"</span></span>);

<span class="pl-c">//We save a AMIDST BN to Hugin format</span>
<span class="pl-smi">BayesianNetwork</span> amidstBN <span class="pl-k">=</span> <span class="pl-smi">BNConverterToAMIDST</span><span class="pl-k">.</span>convertToAmidst(huginBN);
<span class="pl-smi">BNWriterToHugin</span><span class="pl-k">.</span>saveToHuginFile(amidstBN,<span class="pl-s"><span class="pl-pds">"</span>networks/tmp.net<span class="pl-pds">"</span></span>);</pre></div>

<p><a href="#documentation">[Back to Top]</a></p>

<h3>
<a id="invoking-hugins-inference-engine-" class="anchor" href="#invoking-hugins-inference-engine-" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Invoking Hugin's inference engine <a name="huginglinkinferenceexample"></a>
</h3>

<p>This example we show how to perform inference using <a href="http://www.hugin.com">Hugin</a> inference engine within the AMIDST toolbox</p>

<div class="highlight highlight-source-java"><pre><span class="pl-c">//We first load the WasteIncinerator bayesian network </span>
<span class="pl-c">//which has multinomial and Gaussian variables.</span>
<span class="pl-smi">BayesianNetwork</span> bn <span class="pl-k">=</span> <span class="pl-smi">BayesianNetworkLoader</span><span class="pl-k">.</span>loadFromFile(<span class="pl-s"><span class="pl-pds">"</span>./networks/WasteIncinerator.bn<span class="pl-pds">"</span></span>);

<span class="pl-c">//We recover the relevant variables for this example: </span>
<span class="pl-c">//Mout which is normally distributed, and W which is multinomial.</span>
<span class="pl-smi">Variable</span> varMout <span class="pl-k">=</span> bn<span class="pl-k">.</span>getStaticVariables()<span class="pl-k">.</span>getVariableByName(<span class="pl-s"><span class="pl-pds">"</span>Mout<span class="pl-pds">"</span></span>);
<span class="pl-smi">Variable</span> varW <span class="pl-k">=</span> bn<span class="pl-k">.</span>getStaticVariables()<span class="pl-k">.</span>getVariableByName(<span class="pl-s"><span class="pl-pds">"</span>W<span class="pl-pds">"</span></span>);

<span class="pl-c">//First we create an instance of a inference algorithm. </span>
<span class="pl-c">//In this case, we use the ImportanceSampling class.</span>
<span class="pl-smi">InferenceAlgorithm</span> inferenceAlgorithm <span class="pl-k">=</span> <span class="pl-k">new</span> <span class="pl-smi">HuginInference</span>();

<span class="pl-c">//Then, we set the BN model</span>
inferenceAlgorithm<span class="pl-k">.</span>setModel(bn);

<span class="pl-c">//If exists, we also set the evidence.</span>
<span class="pl-smi">Assignment</span> assignment <span class="pl-k">=</span> <span class="pl-k">new</span> <span class="pl-smi">HashMapAssignment</span>(<span class="pl-c1">1</span>);
assignment<span class="pl-k">.</span>setValue(varW,<span class="pl-c1">0</span>);
inferenceAlgorithm<span class="pl-k">.</span>setEvidence(assignment);

<span class="pl-c">//Then we run inference</span>
inferenceAlgorithm<span class="pl-k">.</span>runInference();

<span class="pl-c">//Then we query the posterior of</span>
<span class="pl-smi">System</span><span class="pl-k">.</span>out<span class="pl-k">.</span>println(<span class="pl-s"><span class="pl-pds">"</span>P(Mout|W=0) = <span class="pl-pds">"</span></span> <span class="pl-k">+</span> inferenceAlgorithm<span class="pl-k">.</span>getPosterior(varMout));

<span class="pl-c">//Or some more refined queries</span>
<span class="pl-smi">System</span><span class="pl-k">.</span>out<span class="pl-k">.</span>println(<span class="pl-s"><span class="pl-pds">"</span>P(0.7&lt;Mout&lt;3.5 | W=0) = <span class="pl-pds">"</span></span> 
   <span class="pl-k">+</span> inferenceAlgorithm<span class="pl-k">.</span>getExpectedValue(varMout, v <span class="pl-k">-</span><span class="pl-k">&gt;</span> (<span class="pl-c1">0.7</span> <span class="pl-k">&lt;</span> v <span class="pl-k">&amp;&amp;</span> v <span class="pl-k">&lt;</span> <span class="pl-c1">3.5</span>) <span class="pl-k">?</span> <span class="pl-c1">1.0</span> <span class="pl-k">:</span> <span class="pl-c1">0.0</span> ));</pre></div>

<p><a href="#documentation">[Back to Top]</a></p>

<h3>
<a id="invoking-hugins-parallel-tan-" class="anchor" href="#invoking-hugins-parallel-tan-" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Invoking Hugin's Parallel TAN <a name="huginglinkTANexample"></a>
</h3>

<p>This example we show how to perform inference using <a href="http://www.hugin.com">Hugin</a> inference engine within the AMIDST toolbox</p>

<p>This example shows how to use <a href="http://www.hugin.com">Hugin</a>'s functionality to learn in parallel a TAN model. An important remark is that <a href="http://www.hugin.com">Hugin</a> only allows to learn the TAN model for a data set completely loaded into RAM memory. The case where our data set does not fit into memory, it solved in AMIDST in the following way. We learn the structure using a smaller data set produced by <a href="https://en.wikipedia.org/wiki/Reservoir_sampling">Reservoir sampling</a> and, then, we use AMIDST's <a href="http://amidst.github.io/toolbox/#pmlexample">ParallelMaximumLikelihood</a> to learn the parameters of the TAN model over the whole data set.</p>

<p>For further details about the implementation of the parallel TAN algorithm look at the following paper:</p>

<blockquote>
<p>Madsen, A.L. et al. A New Method for Vertical Parallelisation of TAN Learning Based on Balanced Incomplete Block Designs. Probabilistic Graphical Models. Lecture Notes in Computer Science Volume 8754, 2014, pp 302-317.</p>
</blockquote>

<div class="highlight highlight-source-java"><pre><span class="pl-c">//We load a Bayesian network to generate a data stream</span>
<span class="pl-c">//using BayesianNewtorkSampler class.</span>
<span class="pl-k">int</span> sampleSize <span class="pl-k">=</span> <span class="pl-c1">100000</span>;
<span class="pl-smi">BayesianNetwork</span> bn <span class="pl-k">=</span> <span class="pl-smi">BayesianNetworkLoader</span><span class="pl-k">.</span>loadFromFile(<span class="pl-s"><span class="pl-pds">"</span>networks/Pigs.bn<span class="pl-pds">"</span></span>);
<span class="pl-smi">BayesianNetworkSampler</span> sampler <span class="pl-k">=</span> <span class="pl-k">new</span> <span class="pl-smi">BayesianNetworkSampler</span>(bn);

<span class="pl-c">//We fix the number of samples in memory used for performing the structural learning.</span>
<span class="pl-c">//They are randomly sub-sampled using Reservoir sampling.</span>
<span class="pl-k">int</span> samplesOnMemory <span class="pl-k">=</span> <span class="pl-c1">5000</span>;

<span class="pl-c">//We make different trials with different number of cores</span>
<span class="pl-k">ArrayList&lt;<span class="pl-smi">Integer</span>&gt;</span> vNumCores <span class="pl-k">=</span> <span class="pl-k">new</span> <span class="pl-smi">ArrayList</span>(<span class="pl-smi">Arrays</span><span class="pl-k">.</span>asList(<span class="pl-c1">1</span>, <span class="pl-c1">2</span>, <span class="pl-c1">3</span>, <span class="pl-c1">4</span>));

<span class="pl-k">for</span> (<span class="pl-smi">Integer</span> numCores <span class="pl-k">:</span> vNumCores) {
    <span class="pl-smi">System</span><span class="pl-k">.</span>out<span class="pl-k">.</span>println(<span class="pl-s"><span class="pl-pds">"</span>Learning TAN: <span class="pl-pds">"</span></span> <span class="pl-k">+</span> samplesOnMemory <span class="pl-k">+</span> <span class="pl-s"><span class="pl-pds">"</span> samples on memory, <span class="pl-pds">"</span></span> <span class="pl-k">+</span> numCores <span class="pl-k">+</span> <span class="pl-s"><span class="pl-pds">"</span> core/s ...<span class="pl-pds">"</span></span>);
    <span class="pl-k">DataStream&lt;<span class="pl-smi">DataInstance</span>&gt;</span> data <span class="pl-k">=</span> sampler<span class="pl-k">.</span>sampleToDataStream(sampleSize);

    <span class="pl-c">//The class ParallelTAN is created</span>
    <span class="pl-smi">ParallelTAN</span> tan <span class="pl-k">=</span> <span class="pl-k">new</span> <span class="pl-smi">ParallelTAN</span>();

    <span class="pl-c">//We activate the parallel mode.</span>
    tan<span class="pl-k">.</span>setParallelMode(<span class="pl-c1">true</span>);

    <span class="pl-c">//We set the number of cores to be used for the structural learning</span>
    tan<span class="pl-k">.</span>setNumCores(numCores);

    <span class="pl-c">//We set the number of samples to be used for the learning the structure</span>
    tan<span class="pl-k">.</span>setNumSamplesOnMemory(samplesOnMemory);

    <span class="pl-c">//We set the root variable to be first variable</span>
    tan<span class="pl-k">.</span>setNameRoot(bn<span class="pl-k">.</span>getVariables()<span class="pl-k">.</span>getListOfVariables()<span class="pl-k">.</span>get(<span class="pl-c1">0</span>)<span class="pl-k">.</span>getName());

    <span class="pl-c">//We set the class variable to be the last variable</span>
    tan<span class="pl-k">.</span>setNameTarget(bn<span class="pl-k">.</span>getVariables()<span class="pl-k">.</span>getListOfVariables()<span class="pl-k">.</span>get(bn<span class="pl-k">.</span>getVariables()<span class="pl-k">.</span>getListOfVariables()<span class="pl-k">.</span>size()<span class="pl-k">-</span><span class="pl-c1">1</span>)<span class="pl-k">.</span>getName());

    <span class="pl-smi">Stopwatch</span> watch <span class="pl-k">=</span> <span class="pl-smi">Stopwatch</span><span class="pl-k">.</span>createStarted();

    <span class="pl-c">//We just invoke this mode to learn the TAN model for the data stream</span>
    <span class="pl-smi">BayesianNetwork</span> model <span class="pl-k">=</span> tan<span class="pl-k">.</span>learn(data);

    <span class="pl-smi">System</span><span class="pl-k">.</span>out<span class="pl-k">.</span>println(watch<span class="pl-k">.</span>stop());
}</pre></div>

<h2>
<a id="moalink-" class="anchor" href="#moalink-" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>MoaLink <a name="moalinkexample"></a>
</h2>

<h3>
<a id="amidst-classifiers-from-moa-" class="anchor" href="#amidst-classifiers-from-moa-" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>AMIDST Classifiers from MOA <a name="moalinkclassifiersexample"></a>
</h3>

<p>The following command can be used to learn a Bayesian model with a latent Gaussian variable (HG) and a multinomial with 2 states (HM), as displayed in figure below. The VMP algorithm is used to learn the parameters of these two non-observed variables and make predictions over the class variable.</p>

<p align="center">
<img title="Taxonomy" src="http://amidst.github.io/toolbox/images/HODE.jpg" width="400">
</p>

<pre><code>java -Xmx512m -cp "../lib/*" -javaagent:../lib/sizeofag-1.0.0.jar 
moa.DoTask EvaluatePrequential -l \(bayes.AmidstClassifier -g 1 
-m 2\) -s generators.RandomRBFGenerator -i 10000 -f 1000 -q 1000
</code></pre>

<p><a href="#documentation">[Back to Top]</a></p>

<h3>
<a id="amidst-regression-from-moa-" class="anchor" href="#amidst-regression-from-moa-" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>AMIDST Regression from MOA <a name="moalinkregressionsexample"></a>
</h3>

<p>It is possible to learn an enriched naive Bayes model for regression if the class label is of a continuous nature. The following command uses the model in Figure \ref{fig:HODE}(b) on a toy dataset from WEKA's collection of <a href="http://prdownloads.sourceforge.net/weka/datasets-numeric.jar">regression problems</a>.</p>

<p align="center">
<img title="Taxonomy" src="http://amidst.github.io/toolbox/images/regressionHODE.jpg" width="400">
</p>

<pre><code>java -Xmx512m -cp "../lib/*" -javaagent:../lib/sizeofag-1.0.0.jar 
moa.DoTask EvaluatePrequentialRegression -l bayes.AmidstRegressor
 -s (ArffFileStream -f ./quake.arff)
</code></pre>

<p>Note that the simpler the dataset the less complex the model should be. In this case, \texttt{quake.arff} is a very simple and small dataset that should probably be learn with a more simple classifier, that is, a high-bias-low-variance classifier, in order to avoid overfitting. This aims at providing a simple running example.</p>

<p><a href="#documentation">[Back to Top]</a></p>

      <footer class="site-footer">
        <span class="site-footer-owner"><a href="https://github.com/amidst/toolbox">AMIDST Toolbox 2.0</a> is maintained by <a href="https://github.com/amidst">amidst</a>.</span>

        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the <a href="https://github.com/jasonlong/cayman-theme">Cayman theme</a> by <a href="https://twitter.com/jasonlong">Jason Long</a>.</span>
      </footer>

    </section>

            <script type="text/javascript">
            var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
            document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
          </script>
          <script type="text/javascript">
            try {
              var pageTracker = _gat._getTracker("UA-66233470-1");
            pageTracker._trackPageview();
            } catch(err) {}
          </script>

  </body>
</html>
